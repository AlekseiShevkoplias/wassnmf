{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wassnmf.validation import generate_data\n",
    "from  wassnmf.wassnmf import WassersteinNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario =  {\n",
    "    \"name\": \"gaussian_mixture\",\n",
    "    \"n_samples\": 20,\n",
    "    \"n_features\": 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from geomloss import SamplesLoss  # Sinkhorn-Wasserstein loss\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "def to_tensor(x, requires_grad=False, dtype=torch.float32):\n",
    "    return torch.tensor(x, dtype=dtype, requires_grad=requires_grad)\n",
    "# -------------------------------------------------------------------------\n",
    "# Wasserstein Dictionary Learning\n",
    "# -------------------------------------------------------------------------\n",
    "def train_wdil(X, cost_matrix, n_components=5, lr=0.01, epochs=100):\n",
    "    \"\"\"\n",
    "    Train Wasserstein Dictionary Learning using Sinkhorn gradient descent with a precomputed cost matrix.\n",
    "\n",
    "    X: (n_features, n_samples) histogram data\n",
    "    cost_matrix: (n_features, n_features) cost for 1D transport\n",
    "    \"\"\"\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_torch = to_tensor(X, requires_grad=False)          # shape (n_features, n_samples)\n",
    "    cost_matrix_torch = to_tensor(cost_matrix, requires_grad=False)  # shape (n_features, n_features)\n",
    "\n",
    "    # -- Define a custom cost function that just returns cost_matrix for each sample in the batch --\n",
    "    def cost_fn(x, y):\n",
    "        \"\"\"\n",
    "        x, y: shape (batch_size, n_features, 1) if in measure mode.\n",
    "        We must return shape (batch_size, n_features, n_features) with the cost of each pair of bins.\n",
    "        \"\"\"\n",
    "        if len(x.shape) == 3:  # Handle GeomLoss passing (B, N, 1)\n",
    "            x = x.squeeze(-1)  # Remove last dim if it's (B, N, 1)\n",
    "            y = y.squeeze(-1)\n",
    "\n",
    "        B = x.shape[0]  # Get batch size\n",
    "        return cost_matrix_torch.unsqueeze(0).expand(B, -1, -1)  # Expand cost matrix for each batch\n",
    "\n",
    "    # Initialize Dictionary (D) and Coeffs (R) randomly\n",
    "    n_features, n_samples = X.shape\n",
    "    D = to_tensor(np.abs(np.random.randn(n_features, n_components)), requires_grad=True)\n",
    "    R = to_tensor(np.abs(np.random.randn(n_components, n_samples)), requires_grad=True)\n",
    "\n",
    "    # Define Sinkhorn loss using our custom cost function\n",
    "    sinkhorn_loss = SamplesLoss(\n",
    "        loss=\"sinkhorn\",\n",
    "        cost=cost_fn,   # <--- pass the function, NOT the tensor\n",
    "        blur=0.025,     \n",
    "        debias=False\n",
    "    )\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam([D, R], lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Reconstruction\n",
    "        X_hat = D @ R  # shape (n_features, n_samples)\n",
    "\n",
    "        # Sinkhorn expects (batch_size, n_features) so we do .T\n",
    "        # shape = (n_samples, n_features)\n",
    "        loss = sinkhorn_loss(X_torch.T, X_hat.T)\n",
    "\n",
    "        # Optionally add a sparsity penalty on R\n",
    "        loss += 0.05 * torch.sum(R * torch.log(R + 1e-9))\n",
    "\n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss = {loss.item():.4f}\")\n",
    "\n",
    "    # Return learned dictionary + coefficients in NumPy\n",
    "    return D.detach().numpy(), R.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, K, coord, cost_matrix = generate_data(scenario=scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnmf = WassersteinNMF(n_components=5, verbose=True)\n",
    "D_wass, Lambda_wass = wnmf.fit_transform(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_learned, R_learned = train_wdil(X.T, cost_matrix.T, n_components=5, lr=0.01, epochs=100)\n",
    "print(\"D_learned shape:\", D_learned.shape)\n",
    "print(\"R_learned shape:\", R_learned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = D_learned @ R_learned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_wassnmf = D_wass @ Lambda_wass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X_wassnmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(D_wass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(Lambda_wass)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
